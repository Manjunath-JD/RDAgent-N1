{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ea0417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "\n",
    "def prepreprocess():\n",
    "    # Load the training data\n",
    "    train_df = pd.read_csv(\"/kaggle/input/optiver-realized-volatility-prediction/train.csv\").head(1000)\n",
    "\n",
    "    # Load book and trade data\n",
    "    book_train = pd.read_parquet(\"/kaggle/input/optiver-realized-volatility-prediction/book_train.parquet\").head(1000)\n",
    "    trade_train = pd.read_parquet(\"/kaggle/input/optiver-realized-volatility-prediction/trade_train.parquet\").head(1000)\n",
    "\n",
    "    # Merge book and trade data with train_df\n",
    "    merged_df = pd.merge(train_df, book_train, on=[\"stock_id\", \"time_id\"], how=\"left\")\n",
    "    merged_df = pd.merge(merged_df, trade_train, on=[\"stock_id\", \"time_id\"], how=\"left\")\n",
    "\n",
    "    print(merged_df.head())\n",
    "\n",
    "    # Split the data\n",
    "    X = merged_df.drop([\"target\"], axis=1)\n",
    "    y = merged_df[\"target\"]\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid\n",
    "\n",
    "\n",
    "def preprocess_fit(X_train: pd.DataFrame):\n",
    "    numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in [\"int64\", \"float64\"]]\n",
    "    categorical_cols = [cname for cname in X_train.columns if X_train[cname].dtype == \"object\"]\n",
    "\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"ordinal\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    numerical_transformer = Pipeline(steps=[(\"imputer\", SimpleImputer(strategy=\"mean\"))])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numerical_transformer, numerical_cols),\n",
    "            (\"cat\", categorical_transformer, categorical_cols),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocessor.fit(X_train)\n",
    "\n",
    "    return preprocessor, numerical_cols, categorical_cols\n",
    "\n",
    "\n",
    "def preprocess_transform(X: pd.DataFrame, preprocessor, numerical_cols, categorical_cols):\n",
    "    X_transformed = preprocessor.transform(X)\n",
    "\n",
    "    # Convert arrays back to DataFrames\n",
    "    X_transformed = pd.DataFrame(X_transformed, columns=numerical_cols + categorical_cols, index=X.index)\n",
    "\n",
    "    return X_transformed\n",
    "\n",
    "\n",
    "def preprocess_script():\n",
    "    if os.path.exists(\"/kaggle/input/optiver-realized-volatility-prediction/X_train.pkl\"):\n",
    "        X_train = pd.read_pickle(\"/kaggle/input/optiver-realized-volatility-prediction/X_train.pkl\")\n",
    "        X_valid = pd.read_pickle(\"/kaggle/input/optiver-realized-volatility-prediction/X_valid.pkl\")\n",
    "        y_train = pd.read_pickle(\"/kaggle/input/optiver-realized-volatility-prediction/y_train.pkl\")\n",
    "        y_valid = pd.read_pickle(\"/kaggle/input/optiver-realized-volatility-prediction/y_valid.pkl\")\n",
    "        X_test = pd.read_pickle(\"/kaggle/input/optiver-realized-volatility-prediction/X_test.pkl\")\n",
    "        others = pd.read_pickle(\"/kaggle/input/optiver-realized-volatility-prediction/others.pkl\")\n",
    "\n",
    "        return X_train, X_valid, y_train, y_valid, X_test, *others\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = prepreprocess()\n",
    "\n",
    "    preprocessor, numerical_cols, categorical_cols = preprocess_fit(X_train)\n",
    "\n",
    "    X_train = preprocess_transform(X_train, preprocessor, numerical_cols, categorical_cols)\n",
    "    X_valid = preprocess_transform(X_valid, preprocessor, numerical_cols, categorical_cols)\n",
    "\n",
    "    submission_df = pd.read_csv(\"/kaggle/input/optiver-realized-volatility-prediction/test.csv\")\n",
    "\n",
    "    ids = submission_df[\"row_id\"]\n",
    "    submission_df = submission_df.drop([\"row_id\"], axis=1)\n",
    "\n",
    "    # Add missing columns to submission_df\n",
    "    for col in X_train.columns:\n",
    "        if col not in submission_df.columns:\n",
    "            submission_df[col] = 0  # Fill with 0 or another appropriate value\n",
    "\n",
    "    X_test = preprocess_transform(submission_df, preprocessor, numerical_cols, categorical_cols)\n",
    "\n",
    "    # Handle missing values\n",
    "    for df in [X_train, X_valid, X_test]:\n",
    "        df.fillna(df.mean(), inplace=True)\n",
    "\n",
    "    return X_train, X_valid, y_train, y_valid, X_test, ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\"\n",
    "Here is the feature engineering code for each task, with a class that has a fit and transform method.\n",
    "Remember\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class IdentityFeature:\n",
    "    def fit(self, train_df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Fit the feature engineering model to the training data.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def transform(self, X: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Transform the input data.\n",
    "        \"\"\"\n",
    "        return X\n",
    "\n",
    "\n",
    "feature_cls = IdentityFeature()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af89f99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "class model_randomforest:\n",
    "\n",
    "    def select(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Select relevant features. To be used in fit & predict function.\n",
    "        \"\"\"\n",
    "        # For now, we assume all features are relevant. This can be expanded to feature selection logic.\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series, X_valid: pd.DataFrame, y_valid: pd.Series):\n",
    "        \"\"\"\n",
    "        Define and train the Random Forest model. Merge feature selection into the pipeline.\n",
    "        \"\"\"\n",
    "        # Initialize the Random Forest model\n",
    "        model = RandomForestRegressor(n_estimators=100, random_state=32, n_jobs=-1)\n",
    "    \n",
    "        # Select features (if any feature selection is needed)\n",
    "        X_train_selected = self.select(X_train)\n",
    "        X_valid_selected = self.select(X_valid)\n",
    "    \n",
    "        # Fit the model\n",
    "        model.fit(X_train_selected, y_train)\n",
    "    \n",
    "        # Validate the model\n",
    "        y_valid_pred = model.predict(X_valid_selected)\n",
    "        mse = mean_squared_error(y_valid, y_valid_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        print(f\"Validation RMSE: {rmse:.4f}\")\n",
    "    \n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def predict(self, model, X):\n",
    "        \"\"\"\n",
    "        Keep feature selection's consistency and make predictions.\n",
    "        \"\"\"\n",
    "        # Select features (if any feature selection is needed)\n",
    "        X_selected = self.select(X)\n",
    "    \n",
    "        # Predict using the trained model\n",
    "        y_pred = model.predict(X_selected)\n",
    "    \n",
    "        return y_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82317d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "class model_xgboost:\n",
    "\n",
    "    def select(self, X: pd.DataFrame) -> pd.DataFrame:\n",
    "        # Ignore feature selection logic\n",
    "        return X\n",
    "    \n",
    "    \n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.DataFrame, X_valid: pd.DataFrame, y_valid: pd.DataFrame):\n",
    "        \"\"\"Define and train the model. Merge feature_select\"\"\"\n",
    "        X_train = self.select(X_train)\n",
    "        X_valid = self.select(X_valid)\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
    "    \n",
    "        # Parameters for regression\n",
    "        params = {\n",
    "            \"objective\": \"reg:squarederror\",  # Use squared error for regression\n",
    "            \"nthread\": -1,\n",
    "            \"tree_method\": \"gpu_hist\",\n",
    "            \"device\": \"cuda\",\n",
    "        }\n",
    "        num_round = 200\n",
    "    \n",
    "        evallist = [(dtrain, \"train\"), (dvalid, \"eval\")]\n",
    "        bst = xgb.train(params, dtrain, num_round, evallist)\n",
    "    \n",
    "        return bst\n",
    "    \n",
    "    \n",
    "    def predict(self, model, X):\n",
    "        \"\"\"\n",
    "        Keep feature select's consistency.\n",
    "        \"\"\"\n",
    "        X = self.select(X)\n",
    "        dtest = xgb.DMatrix(X)\n",
    "        y_pred = model.predict(dtest)\n",
    "        return y_pred.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd5ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "DIRNAME = Path(__file__).absolute().resolve().parent\n",
    "\n",
    "\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    \"\"\"Compute RMSE for regression.\"\"\"\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse\n",
    "\n",
    "\n",
    "def import_module_from_path(module_name, module_path):\n",
    "    spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module\n",
    "\n",
    "\n",
    "print(\"begin preprocess\")\n",
    "# 1) Preprocess the data\n",
    "X_train, X_valid, y_train, y_valid, X_test, ids = preprocess_script()\n",
    "print(\"preprocess done\")\n",
    "\n",
    "# 2) Auto feature engineering\n",
    "X_train_l, X_valid_l = [], []\n",
    "X_test_l = []\n",
    "\n",
    "for cls in [feature_cls]:\n",
    "    \n",
    "    cls.fit(X_train)\n",
    "    X_train_f = cls.transform(X_train)\n",
    "    X_valid_f = cls.transform(X_valid)\n",
    "    X_test_f = cls.transform(X_test)\n",
    "\n",
    "    X_train_l.append(X_train_f)\n",
    "    X_valid_l.append(X_valid_f)\n",
    "    X_test_l.append(X_test_f)\n",
    "\n",
    "X_train = pd.concat(X_train_l, axis=1, keys=[f\"feature_{i}\" for i in range(len(X_train_l))])\n",
    "X_valid = pd.concat(X_valid_l, axis=1, keys=[f\"feature_{i}\" for i in range(len(X_valid_l))])\n",
    "X_test = pd.concat(X_test_l, axis=1, keys=[f\"feature_{i}\" for i in range(len(X_test_l))])\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "\n",
    "# Handle inf and -inf values\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_valid.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "X_train = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns)\n",
    "X_valid = pd.DataFrame(imputer.transform(X_valid), columns=X_valid.columns)\n",
    "X_test = pd.DataFrame(imputer.transform(X_test), columns=X_test.columns)\n",
    "\n",
    "# Remove duplicate columns\n",
    "X_train = X_train.loc[:, ~X_train.columns.duplicated()]\n",
    "X_valid = X_valid.loc[:, ~X_valid.columns.duplicated()]\n",
    "X_test = X_test.loc[:, ~X_test.columns.duplicated()]\n",
    "\n",
    "\n",
    "# 3) Train the model\n",
    "def flatten_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Flatten the columns of a DataFrame with MultiIndex columns,\n",
    "    for (feature_0, a), (feature_0, b) -> feature_0_a, feature_0_b\n",
    "    \"\"\"\n",
    "    if df.columns.nlevels == 1:\n",
    "        return df\n",
    "    df.columns = [\"_\".join(col).strip() for col in df.columns.values]\n",
    "    return df\n",
    "\n",
    "\n",
    "X_train = flatten_columns(X_train)\n",
    "X_valid = flatten_columns(X_valid)\n",
    "X_test = flatten_columns(X_test)\n",
    "\n",
    "model_l = []  # list[tuple[model, predict_func,]]\n",
    "for mc in [model_randomforest, model_xgboost]:\n",
    "    m = mc()\n",
    "    model_l.append((m.fit(X_train, y_train, X_valid, y_valid), m.predict))\n",
    "\n",
    "# 4) Evaluate the model on the validation set\n",
    "y_valid_pred_l = []\n",
    "for model, predict_func in model_l:\n",
    "    y_valid_pred_l.append(predict_func(model, X_valid))\n",
    "    print(predict_func(model, X_valid).shape)\n",
    "\n",
    "# 5) Ensemble\n",
    "y_valid_pred = np.mean(y_valid_pred_l, axis=0)\n",
    "\n",
    "rmse = compute_rmse(y_valid, y_valid_pred)\n",
    "print(\"Final RMSE on validation set: \", rmse)\n",
    "\n",
    "# 6) Save the validation RMSE\n",
    "pd.Series(data=[rmse], index=[\"RMSE\"]).to_csv(\"submission_score.csv\")\n",
    "\n",
    "# 7) Make predictions on the test set and save them\n",
    "y_test_pred_l = []\n",
    "for m, m_pred in model_l:\n",
    "    y_test_pred_l.append(m_pred(m, X_test))\n",
    "\n",
    "y_test_pred = np.mean(y_test_pred_l, axis=0).ravel()\n",
    "\n",
    "# 8) Submit predictions for the test set\n",
    "submission_result = pd.DataFrame({\"id\": ids, \"price\": y_test_pred})\n",
    "submission_result.to_csv(\"submission.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
